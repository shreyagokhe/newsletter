{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] cO3QvioMESo: Downloading webpage\n",
      "[youtube] Downloading just video cO3QvioMESo because of --no-playlist\n",
      "[youtube] cO3QvioMESo: Downloading MPD manifest\n",
      "[dashsegments] Total fragments: 100\n",
      "[download] Destination: cO3QvioMESo.m4a\n",
      "[download] 100% of 15.18MiB in 00:11                    \n",
      "[ffmpeg] Correcting container in \"cO3QvioMESo.m4a\"\n",
      "[ffmpeg] Destination: cO3QvioMESo.wav\n",
      "Deleting original file cO3QvioMESo.m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals #you are building a byte string that holds UTF-8 encoded bytes.\n",
    "                                        #With the string you are building a unicode string.\n",
    "import youtube_dl #Command-line program to download videos from YouTube.com and other video sites\n",
    "\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',     #getting the best format\n",
    "    'extractaudio':True,            #only extract audio\n",
    "    'audioformat':'wav',            #save audio in .wav format-- easy to convert as most recordings are in .wav\n",
    "    'outtmpl':'%(id)s.%(ext)s',     #name the file as the ID of the video\n",
    "    'noplaylist':True,              #no playlist download\n",
    "    'nocheckcertificate':True,       \n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio', #asks to extract audio\n",
    "        'preferredcodec': 'wav',     #file type\n",
    "        'preferredquality': '192',   #quality index\n",
    "    }],\n",
    "}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(['https://www.youtube.com/watch?v=cO3QvioMESo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                #provides functions for interacting with the operating system\n",
    "import speech_recognition as sr     #library to perform speech recognition\n",
    "\n",
    "from pydub import AudioSegment      #, if there are several overlapping sounds in this AudioSegment,this \n",
    "                                     #method will return one AudioSegment object for each of those sounds. \n",
    "from pydub.silence import split_on_silence     #if there is silence in the vid, then we will split the sound\n",
    "\n",
    "r = sr.Recognizer()           # a function that splits the audio file into chunks\n",
    "                                    # and applies speech recognition\n",
    "                                \n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    sound = AudioSegment.from_wav(path)   # open the audio file using pydub\n",
    "    \n",
    "    fh = open(\"converted.txt\", \"w+\")  #open the file to write\n",
    "    chunks = split_on_silence(sound,   # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "       \n",
    "        min_silence_len = 500,    # experiment with this value for your target audio file\n",
    "        \n",
    "        silence_thresh = sound.dBFS-14,  # adjust this per requirement\n",
    "        \n",
    "        keep_silence=500,   # keep the silence for 1 second, adjustable as well\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"     # create a directory to store the audio chunks\n",
    "   \n",
    "    if not os.path.isdir(folder_name):    # asking os to create such foldername if not present and passing the text \n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):     # export audio chunk and save it in\n",
    "                                                         # the `folder_name` directory.\n",
    "        \n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")       # recognize the chunk\n",
    "       \n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)               # try converting it to text\n",
    "            \n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "                fh.write(text+\". \")      #writing in the .txt file\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "                                         # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : I'm heather noelis and i was the first machine learning engineer hired to be on the ait mat. \n",
      "audio-chunks\\chunk2.wav : T-mobile. \n",
      "audio-chunks\\chunk3.wav : Can i talk to you a little bit about how we actually use are in production at t-mobile in the steps that you can do to do it as well because i know that nobody loves handing off their beautiful code to somebody else to just rewrite in python. \n",
      "audio-chunks\\chunk4.wav : And so what do we actually do our goal is not to build a chatbot when you hear lots of organizations talk about doing natural language processing in real time you think chatbots. \n",
      "audio-chunks\\chunk5.wav : Pergolas to essentially build a tool that the customer can interact or that the agent can interact with to help customers. \n",
      "audio-chunks\\chunk6.wav : So i have a little screenshot of a sample of a tool that we have that. \n",
      "audio-chunks\\chunk7.wav : If somebody says hello i'm traveling to europe and i need to make sure my phone works when you run it through an intent model we say you're talking about unlocked so let's go get some account information about this individual that the agent will need to help you and then let's do an information retrieval and see internal wikipedia articles that the agent can look at the services customer really quickly so the goal here is not again to build chatbots and put something in front of the user. \n",
      "audio-chunks\\chunk8.wav : It's to build tools that actually help the agent help you faster. \n",
      "audio-chunks\\chunk9.wav : And so i said i'm going to talk about putting our introduction but what does that actually mean it's basically whenever you're sitting on your computer you're working at rmarkdown file you're doing an analysis you run your code wants to get the result. \n",
      "audio-chunks\\chunk10.wav : Then you build it and that's cool that's continuously running anybody can come up to your laptop at any time and see that that code is running. \n",
      "audio-chunks\\chunk11.wav : I'm putting into production means putting it somewhere that's outside of your laptop where it lives all the time and that users can always interact with it's always on it's always running. \n",
      "audio-chunks\\chunk12.wav : And so i'm piggybacking off of jacqueline's presentation yesterday we're going to take the pet name generator the big tensorflow deep learning model that she created and we are going to put it into production in my talk so if she handed me this code what are the things that i would have to do to make it actually run scalable at t-mobile. \n",
      "audio-chunks\\chunk13.wav : I thought we do this with apis and people say api all the time and it sounds really intimidating but all in api is if every time that you go to a website on your phone you are hitting an api. \n",
      "audio-chunks\\chunk14.wav : An api is just a way of getting information from the internet instead of from a console so you guys have apis all the time and are two ways that people primarily hit apis every time that you go to a website that's a get request you're saying. \n",
      "audio-chunks\\chunk15.wav : Weather.com please tell me. \n",
      "audio-chunks\\chunk16.wav : What. \n",
      "audio-chunks\\chunk17.wav : Information i want to see like i want to get the weather of the day. \n",
      "audio-chunks\\chunk18.wav : Or you can do a. \n",
      "audio-chunks\\chunk19.wav : Post request which would just be like. \n",
      "audio-chunks\\chunk20.wav : I want to add my name to your website i want to sign up for a mailing list so here's my name website and do whatever you want with it. \n",
      "audio-chunks\\chunk21.wav : And so a get request is just going to a website or getting any information from the internet and so for us what that means is that we need to convert the variables that it sends to us so i can use it. \n",
      "audio-chunks\\chunk22.wav : We need to make a prediction on those variables in return the results and that's it so if you remember yesterday where we left off with jacquelyn she'd created a nice function that was just to return to bunch of predictions. \n",
      "audio-chunks\\chunk23.wav : So in this case i would say i want to get 20 pet names. \n",
      "audio-chunks\\chunk24.wav : And then the model would run in generate 25 names and then would give it back to me. \n",
      "audio-chunks\\chunk25.wav : That's all in apison engineer say and they talk really lofty they're all lying to you it's not that complicated. \n",
      "audio-chunks\\chunk26.wav : And we do that with plumber which is a package developed by our studio that is literally the easiest thing in the entire world. \n",
      "audio-chunks\\chunk27.wav : So it is i'm not kidding it takes these three lines of code and that's all it takes. \n",
      "audio-chunks\\chunk28.wav : To make what jacqueline put on the screen yesterday into an api. \n",
      "audio-chunks\\chunk29.wav : So all you have to do is import plumber. \n",
      "audio-chunks\\chunk30.wav : Show plumber where the endpoints are in a limb points are our what comes after the / okay went to weather.com seattle the endpoint is seattle part of the url. \n",
      "audio-chunks\\chunk31.wav : What are the things after the slash. \n",
      "audio-chunks\\chunk32.wav : Open a port to the internet which means that anybody can talk to you import plummer and you've done it you've built an api so when engineers make the sound really complicated. \n",
      "audio-chunks\\chunk33.wav : It's three lines of r code anybody here can do it. \n",
      "audio-chunks\\chunk34.wav : Like i said you first you just create a file for the endpoint so if you look here. \n",
      "audio-chunks\\chunk35.wav : It just says i'm going to use a get function and i want to get names. \n",
      "audio-chunks\\chunk36.wav : Return the this is exactly the function that jacqueline date yesterday to just return many names 20 names that we do the import and then you go to the website on your computer. \n",
      "audio-chunks\\chunk37.wav : And it returns a result. \n",
      "audio-chunks\\chunk38.wav : Boots like. \n",
      "audio-chunks\\chunk39.wav : Incredibly easy. \n",
      "audio-chunks\\chunk40.wav : You just run your function. \n",
      "audio-chunks\\chunk41.wav : Go to the actual port that you open to the internet and then you feel super powerful cuz you did a thing that engineers bragged about doing and say that you can't do in our all the time but. \n",
      "audio-chunks\\chunk42.wav : 6 lines of code. \n",
      "audio-chunks\\chunk43.wav : I build java services in this is way easier. \n",
      "audio-chunks\\chunk44.wav : And we really love plumber like. \n",
      "audio-chunks\\chunk45.wav : I always say that shine your plumber should really be like. \n",
      "audio-chunks\\chunk46.wav : I should be giving him an award because they're paying for my house at the. \n",
      "audio-chunks\\chunk47.wav : It's a really really demonstrate that i have a totally unprompted. \n",
      "audio-chunks\\chunk48.wav : Sample of my son he was 16 months old at the time. \n",
      "audio-chunks\\chunk49.wav : He always ask me what's on my laptop and so here's an example of how much in my family we love plumber. \n",
      "audio-chunks\\chunk50.wav : Amber. \n",
      "audio-chunks\\chunk51.wav : Who is this. \n",
      "audio-chunks\\chunk52.wav : Plumber yea. \n",
      "audio-chunks\\chunk53.wav : I thought my 16 month old child who only knows like slide in agua also knows what plumber is because that's how important plumber is to me. \n",
      "audio-chunks\\chunk54.wav : I thought you felt it lives on your laptop you have an api and hit a senior api sucks. \n",
      "audio-chunks\\chunk55.wav : Because you have to be your laptop have to be connected to the internet you have to be running your code and you have to just have it there waiting for them. \n",
      "audio-chunks\\chunk56.wav : Nobody wants to live their life like that just having their laptop waiting for some. \n",
      "audio-chunks\\chunk57.wav : Probably jerk to be like can i please access your model so we're going to put it in the cloud which is again another thing that engineers say. \n",
      "audio-chunks\\chunk58.wav : What does it mean. \n",
      "audio-chunks\\chunk59.wav : It's over all the parties are giant laptops in the sky that somebody else owns. \n",
      "audio-chunks\\chunk60.wav : And it's literally it's so if you have it on your laptop sitting there you didn't put it on somebody else's laptop you know all the stuff. \n",
      "audio-chunks\\chunk61.wav : What we need for our api that jack built to work we just need an operating system the correct version of are all of the libraries that you think that you need. \n",
      "audio-chunks\\chunk62.wav : What you just wrote those three little lines of code and everything exactly should you yesterday and then just open a port to the internet. \n",
      "audio-chunks\\chunk63.wav : And so we've already done that on our laptops to let's talk about how we would do that in the cloud. \n",
      "audio-chunks\\chunk64.wav : It would be exactly the same you would install rstudio you would go through the exact same stuff that jacqueline did yesterday and you would do my last two slides. \n",
      "audio-chunks\\chunk65.wav : Super super easy to do on a virtual machine which is somebody else's sky laptop. \n",
      "audio-chunks\\chunk66.wav : The downsides of using a virtual machine is laptops are expensive right like every time that you get a new laptop and you have to set it up it takes quite a bit of time to do that the companies paying you that time to like reset up the sky laptops. \n",
      "audio-chunks\\chunk67.wav : It takes a lot of time the setup is probably undocumented i have a file at like all the special things when i get a new computer that i want to put on my computer but i do know you probably have to install a bunch of weird javascript plugins all the time and then you forget that you use this one packaging you have to reinstall everything so that's all undocumented so if you were to leave the company. \n",
      "audio-chunks\\chunk68.wav : They couldn't recreate your computer if somebody turned off your sky computer they couldn't recreate it. \n",
      "audio-chunks\\chunk69.wav : And so since good engineering is repeatable. \n",
      "audio-chunks\\chunk70.wav : That probably isn't good engineering to just set up a virtual. \n",
      "audio-chunks\\chunk71.wav : So what can we do that is. \n",
      "audio-chunks\\chunk72.wav : Super super repeatable. \n",
      "audio-chunks\\chunk73.wav : How can we document this. \n",
      "audio-chunks\\chunk74.wav : And that's all containers are people talk about containers they talk about docker. \n",
      "audio-chunks\\chunk75.wav : Containers are cheaper there is less computational overhead cuz you don't need to use a whole computer every time there's super trendy so people think that you're doing really cutting-edge technology when you talk about it they're made to crash and be restarted so every time that you restart your computer it takes forever to restart a docker container. \n",
      "audio-chunks\\chunk76.wav : And then scaling and coordinating is easy so i can say this docker container is out there living but i started up this one until just redirect rap. \n",
      "audio-chunks\\chunk77.wav : So i can just my old models hear my new models here let's just. \n",
      "audio-chunks\\chunk78.wav : Which words. \n",
      "audio-chunks\\chunk79.wav : Pointing and that's all kubernetes is if anyone's ever thrown that word that you do is just how do we tell which container reporting at again not super complicated. \n",
      "audio-chunks\\chunk80.wav : Dark and heavy. \n",
      "Error: \n",
      "audio-chunks\\chunk82.wav : All that doctor is is the repeatable steps that you need to setup a virtual machine the repeatable steps were if i was to give you a laptop and say write down everything that you need to run my api under machine we just write it so computer can do that so we don't have to have people sitting there forever well. \n",
      "audio-chunks\\chunk83.wav : Rstudio downloads for the 89th time because i'm really bad at building models and i need to be deployed 89 times before one works. \n",
      "Error: \n",
      "audio-chunks\\chunk85.wav : Is there a what this means that you can run docker. \n",
      "audio-chunks\\chunk86.wav : Encore you can bring your our code on computers that don't have are installed. \n",
      "audio-chunks\\chunk87.wav : Because you installed in the container and the container look on the computer. \n",
      "audio-chunks\\chunk88.wav : So you can take it to your mom's house be like mom run this really cool code on your computer and you don't remind her through all the ridiculous set-up steps. \n",
      "audio-chunks\\chunk89.wav : At the end of the day i choose kind of like a little steps and they don't care about what you're actually doing they just want it to work. \n",
      "audio-chunks\\chunk90.wav : Kid doctor goes ahead and takes care of all of that for you never have to worry about if you install a certain our package doesn't break somebody else's code cuz he put it in a nice little container that contains it and keeps it from breaking everybody else's stuff that's really where the name comes from. \n",
      "audio-chunks\\chunk91.wav : But what does that look like. \n",
      "audio-chunks\\chunk92.wav : So we have a dockerfile and like i said that's just a list of instructions that would be used to set up your computer at any time. \n",
      "audio-chunks\\chunk93.wav : Do you have the image which is after somebody builds that dockerfile and sets up the computer like you want that's the image and when you run it that's the container so people will throw these words that you will not but they're all really the same things just in different forms of the process. \n",
      "Error: \n",
      "audio-chunks\\chunk95.wav : Now i need my prop. \n",
      "audio-chunks\\chunk96.wav : Thank you. \n",
      "audio-chunks\\chunk97.wav : It's a disney pet names dockerfile for the api. jackson building her talk yesterday. \n",
      "audio-chunks\\chunk98.wav : It's okay just have a starting image which we use rocker which is just an r docker image. \n",
      "audio-chunks\\chunk99.wav : And then there's some lenox libraries we have to import python because carrots runs on python let me copy over our scripts install are libraries open up the port and then just say run the main function. \n",
      "audio-chunks\\chunk100.wav : But there's a trick when you look at this. \n",
      "audio-chunks\\chunk101.wav : The first thing that it says is rocker version. \n",
      "audio-chunks\\chunk102.wav : Three-point whatever. \n",
      "audio-chunks\\chunk103.wav : But what does that look like. \n",
      "audio-chunks\\chunk104.wav : Well that's a lot of fun and it actually it's if it's a lot a lot of code it's a good way to think about docker images. \n",
      "audio-chunks\\chunk105.wav : Is to think about nesting dolls so the first image that i showed you. \n",
      "audio-chunks\\chunk106.wav : This is kind of your finished product. \n",
      "audio-chunks\\chunk107.wav : But that front line and kind of open it up. \n",
      "audio-chunks\\chunk108.wav : Is it okay okay so it's built on something simpler somebody else with a lot of words to this is the next event you say okay. \n",
      "audio-chunks\\chunk109.wav : Sure but that also has an import line it's from davion which is an operating system. \n",
      "audio-chunks\\chunk110.wav : So you can look at it nike okay so now we have a level smaller even. \n",
      "audio-chunks\\chunk111.wav : What's this. \n",
      "audio-chunks\\chunk112.wav : There's another one. \n",
      "audio-chunks\\chunk113.wav : So you got to open at night okay so finally finally we reached the end. \n",
      "audio-chunks\\chunk114.wav : Isn't this is what you're doing every time that you make a container which is what makes darker stove in usable is that i'm able to say this is davion build on top of that. \n",
      "audio-chunks\\chunk115.wav : Now we have some other thing and then on top of that then. \n",
      "audio-chunks\\chunk116.wav : Somewhere in there you can just take all the stuff that other people are building that's much simpler and say add my little specific things add my more details and make it more beautiful so at the end really you just have to say look at my beautiful finish product but you're leveraging like. \n",
      "audio-chunks\\chunk117.wav : Thousands of thousands of lines of code the other people. \n",
      "audio-chunks\\chunk118.wav : It's open to actually run your container you just. \n",
      "audio-chunks\\chunk119.wav : On your computer it's where you would run it first just. \n",
      "audio-chunks\\chunk120.wav : Just make sure it works you can install docker on your computer. \n",
      "audio-chunks\\chunk121.wav : Then open the console build damage and run it and it would run exactly the same as it didn't rstudio but now you can do that in a computer that doesn't have our install. \n",
      "audio-chunks\\chunk122.wav : It's a what's left. \n",
      "audio-chunks\\chunk123.wav : You've done all of this work you've put your thing in a docker container engineering departments are really impressed devops is like i understand what you're doing now and they take are seriously. \n",
      "audio-chunks\\chunk124.wav : Therapeutic that you have to think about you have to think about how can you encrypt your api to make it super secure how can you add logging so that way devops is happy with you how can you write unit tests to prove that your code is working and not absolutely broken and is returning as expected. \n",
      "audio-chunks\\chunk125.wav : Another thing is if you want to talk about those three things i can talk about them to you forever like forever and ever and ever and ever my background software engineering and this is really all we do at the end of the day. \n",
      "audio-chunks\\chunk126.wav : I think you need to release your code which just means put it out into the world that way people get to play with it. \n",
      "audio-chunks\\chunk127.wav : I know we do that at t-mobile as we have a very complicated software engineering pipeline. \n",
      "audio-chunks\\chunk128.wav : So when you check something into bitbucket which is like our github paycheck something in a fella named jenkins build damage for you which is just going through this dockerfile steps in setting up the machine just like you act. \n",
      "audio-chunks\\chunk129.wav : Animarathon which is like cheap kubernetes does the does the release so it puts it out somewhere on to the internet. \n",
      "audio-chunks\\chunk130.wav : And then made those just host the container so that's the website where would actually live. \n",
      "audio-chunks\\chunk131.wav : But you guys don't have time for that. \n",
      "audio-chunks\\chunk132.wav : That's that's a lot that's a lot of engineering. \n",
      "audio-chunks\\chunk133.wav : So you can just do it. \n",
      "audio-chunks\\chunk134.wav : There's a thing called elastic container store and elastic container repository italy. \n",
      "audio-chunks\\chunk135.wav : And if you just go to aws you can say here's my documents they will build it for you and they will host just that image it will automatically get more research sources whenever you need it took a ton of people are hitting your in point it'll say okay let's make this bigger and if nobody ever uses. \n",
      "audio-chunks\\chunk136.wav : Super super great. \n",
      "audio-chunks\\chunk137.wav : And so this really works this is a doctor like this is exactly how we productionize this for our consulting firms websites to right now you could go to pets. no less llc.com name and it will return you the stuff that jacksonville yesterday exactly the stuff that we went through. \n",
      "audio-chunks\\chunk138.wav : Please don't hit it all at once because we don't have auto scaling on it because we are incredibly cheap but anybody at any point could go and use this and so i didn't mention it yesterday but when we first made the deep learning container that generated these pet names we shopped it around to a lot of shelters in the seattle area please it'll be so funny. \n",
      "audio-chunks\\chunk139.wav : We really don't care about the fancy technology that you've applied. \n",
      "audio-chunks\\chunk140.wav : But if you know what shelter who wants to name their their animals from deep learning names we have a thing that you can have any point and sell our project for us anybody can use it for free if you name your pet after any of these names generated by a girl that work i will give you. \n",
      "audio-chunks\\chunk141.wav : A whole dollar. \n",
      "audio-chunks\\chunk142.wav : It really works it's super cool i love it. \n",
      "audio-chunks\\chunk143.wav : And so the takeaways are that. \n",
      "audio-chunks\\chunk144.wav : The stuff that engineers talked about its being so complicated really isn't. \n",
      "audio-chunks\\chunk145.wav : And. \n",
      "audio-chunks\\chunk146.wav : Working on. \n",
      "audio-chunks\\chunk147.wav : The first project at t-mobile where we really had data scientist and engineers a machine-learning people on the room side by side. \n",
      "audio-chunks\\chunk148.wav : It taught us that the disparities between the two disciplines are actually very small. \n",
      "audio-chunks\\chunk149.wav : And so if you guys can build a really complicated model with you all can you can absolutely add logging it's one line of code you can create an api it's three lines of code. \n",
      "audio-chunks\\chunk150.wav : You can deploy an api doctors really just writing down the steps that you already do every single time that you install something on your laptop so this is stuff that you can do to stop letting engineering people take away your work unless you find this terribly boring. \n",
      "audio-chunks\\chunk151.wav : You don't have to let engineers take away your work even levenger companies engineering department you can just throw it up on aws and it it all that's out the same. \n",
      "audio-chunks\\chunk152.wav : There was a thank you for sitting and listening to me tell you about how much i love doctor again if you want to talk about any of this for any length of time i absolutely want to. \n",
      "audio-chunks\\chunk153.wav : Double extra thank you to my son who allowed both of his mom's to be here today instead of hanging out with him especially his mother's day weekend and then the code is available on github for the whole thing so jacqueline's neural network down to dockerizing it is all available on the noelis llc. \n",
      "audio-chunks\\chunk154.wav : And you can follow me on twitter at heathercliff they talked about engineering. \n",
      "audio-chunks\\chunk155.wav : Thank you. \n",
      "Error: \n",
      "\n",
      "Full text: I'm heather noelis and i was the first machine learning engineer hired to be on the ait mat. T-mobile. Can i talk to you a little bit about how we actually use are in production at t-mobile in the steps that you can do to do it as well because i know that nobody loves handing off their beautiful code to somebody else to just rewrite in python. And so what do we actually do our goal is not to build a chatbot when you hear lots of organizations talk about doing natural language processing in real time you think chatbots. Pergolas to essentially build a tool that the customer can interact or that the agent can interact with to help customers. So i have a little screenshot of a sample of a tool that we have that. If somebody says hello i'm traveling to europe and i need to make sure my phone works when you run it through an intent model we say you're talking about unlocked so let's go get some account information about this individual that the agent will need to help you and then let's do an information retrieval and see internal wikipedia articles that the agent can look at the services customer really quickly so the goal here is not again to build chatbots and put something in front of the user. It's to build tools that actually help the agent help you faster. And so i said i'm going to talk about putting our introduction but what does that actually mean it's basically whenever you're sitting on your computer you're working at rmarkdown file you're doing an analysis you run your code wants to get the result. Then you build it and that's cool that's continuously running anybody can come up to your laptop at any time and see that that code is running. I'm putting into production means putting it somewhere that's outside of your laptop where it lives all the time and that users can always interact with it's always on it's always running. And so i'm piggybacking off of jacqueline's presentation yesterday we're going to take the pet name generator the big tensorflow deep learning model that she created and we are going to put it into production in my talk so if she handed me this code what are the things that i would have to do to make it actually run scalable at t-mobile. I thought we do this with apis and people say api all the time and it sounds really intimidating but all in api is if every time that you go to a website on your phone you are hitting an api. An api is just a way of getting information from the internet instead of from a console so you guys have apis all the time and are two ways that people primarily hit apis every time that you go to a website that's a get request you're saying. Weather.com please tell me. What. Information i want to see like i want to get the weather of the day. Or you can do a. Post request which would just be like. I want to add my name to your website i want to sign up for a mailing list so here's my name website and do whatever you want with it. And so a get request is just going to a website or getting any information from the internet and so for us what that means is that we need to convert the variables that it sends to us so i can use it. We need to make a prediction on those variables in return the results and that's it so if you remember yesterday where we left off with jacquelyn she'd created a nice function that was just to return to bunch of predictions. So in this case i would say i want to get 20 pet names. And then the model would run in generate 25 names and then would give it back to me. That's all in apison engineer say and they talk really lofty they're all lying to you it's not that complicated. And we do that with plumber which is a package developed by our studio that is literally the easiest thing in the entire world. So it is i'm not kidding it takes these three lines of code and that's all it takes. To make what jacqueline put on the screen yesterday into an api. So all you have to do is import plumber. Show plumber where the endpoints are in a limb points are our what comes after the / okay went to weather.com seattle the endpoint is seattle part of the url. What are the things after the slash. Open a port to the internet which means that anybody can talk to you import plummer and you've done it you've built an api so when engineers make the sound really complicated. It's three lines of r code anybody here can do it. Like i said you first you just create a file for the endpoint so if you look here. It just says i'm going to use a get function and i want to get names. Return the this is exactly the function that jacqueline date yesterday to just return many names 20 names that we do the import and then you go to the website on your computer. And it returns a result. Boots like. Incredibly easy. You just run your function. Go to the actual port that you open to the internet and then you feel super powerful cuz you did a thing that engineers bragged about doing and say that you can't do in our all the time but. 6 lines of code. I build java services in this is way easier. And we really love plumber like. I always say that shine your plumber should really be like. I should be giving him an award because they're paying for my house at the. It's a really really demonstrate that i have a totally unprompted. Sample of my son he was 16 months old at the time. He always ask me what's on my laptop and so here's an example of how much in my family we love plumber. Amber. Who is this. Plumber yea. I thought my 16 month old child who only knows like slide in agua also knows what plumber is because that's how important plumber is to me. I thought you felt it lives on your laptop you have an api and hit a senior api sucks. Because you have to be your laptop have to be connected to the internet you have to be running your code and you have to just have it there waiting for them. Nobody wants to live their life like that just having their laptop waiting for some. Probably jerk to be like can i please access your model so we're going to put it in the cloud which is again another thing that engineers say. What does it mean. It's over all the parties are giant laptops in the sky that somebody else owns. And it's literally it's so if you have it on your laptop sitting there you didn't put it on somebody else's laptop you know all the stuff. What we need for our api that jack built to work we just need an operating system the correct version of are all of the libraries that you think that you need. What you just wrote those three little lines of code and everything exactly should you yesterday and then just open a port to the internet. And so we've already done that on our laptops to let's talk about how we would do that in the cloud. It would be exactly the same you would install rstudio you would go through the exact same stuff that jacqueline did yesterday and you would do my last two slides. Super super easy to do on a virtual machine which is somebody else's sky laptop. The downsides of using a virtual machine is laptops are expensive right like every time that you get a new laptop and you have to set it up it takes quite a bit of time to do that the companies paying you that time to like reset up the sky laptops. It takes a lot of time the setup is probably undocumented i have a file at like all the special things when i get a new computer that i want to put on my computer but i do know you probably have to install a bunch of weird javascript plugins all the time and then you forget that you use this one packaging you have to reinstall everything so that's all undocumented so if you were to leave the company. They couldn't recreate your computer if somebody turned off your sky computer they couldn't recreate it. And so since good engineering is repeatable. That probably isn't good engineering to just set up a virtual. So what can we do that is. Super super repeatable. How can we document this. And that's all containers are people talk about containers they talk about docker. Containers are cheaper there is less computational overhead cuz you don't need to use a whole computer every time there's super trendy so people think that you're doing really cutting-edge technology when you talk about it they're made to crash and be restarted so every time that you restart your computer it takes forever to restart a docker container. And then scaling and coordinating is easy so i can say this docker container is out there living but i started up this one until just redirect rap. So i can just my old models hear my new models here let's just. Which words. Pointing and that's all kubernetes is if anyone's ever thrown that word that you do is just how do we tell which container reporting at again not super complicated. Dark and heavy. All that doctor is is the repeatable steps that you need to setup a virtual machine the repeatable steps were if i was to give you a laptop and say write down everything that you need to run my api under machine we just write it so computer can do that so we don't have to have people sitting there forever well. Rstudio downloads for the 89th time because i'm really bad at building models and i need to be deployed 89 times before one works. Is there a what this means that you can run docker. Encore you can bring your our code on computers that don't have are installed. Because you installed in the container and the container look on the computer. So you can take it to your mom's house be like mom run this really cool code on your computer and you don't remind her through all the ridiculous set-up steps. At the end of the day i choose kind of like a little steps and they don't care about what you're actually doing they just want it to work. Kid doctor goes ahead and takes care of all of that for you never have to worry about if you install a certain our package doesn't break somebody else's code cuz he put it in a nice little container that contains it and keeps it from breaking everybody else's stuff that's really where the name comes from. But what does that look like. So we have a dockerfile and like i said that's just a list of instructions that would be used to set up your computer at any time. Do you have the image which is after somebody builds that dockerfile and sets up the computer like you want that's the image and when you run it that's the container so people will throw these words that you will not but they're all really the same things just in different forms of the process. Now i need my prop. Thank you. It's a disney pet names dockerfile for the api. jackson building her talk yesterday. It's okay just have a starting image which we use rocker which is just an r docker image. And then there's some lenox libraries we have to import python because carrots runs on python let me copy over our scripts install are libraries open up the port and then just say run the main function. But there's a trick when you look at this. The first thing that it says is rocker version. Three-point whatever. But what does that look like. Well that's a lot of fun and it actually it's if it's a lot a lot of code it's a good way to think about docker images. Is to think about nesting dolls so the first image that i showed you. This is kind of your finished product. But that front line and kind of open it up. Is it okay okay so it's built on something simpler somebody else with a lot of words to this is the next event you say okay. Sure but that also has an import line it's from davion which is an operating system. So you can look at it nike okay so now we have a level smaller even. What's this. There's another one. So you got to open at night okay so finally finally we reached the end. Isn't this is what you're doing every time that you make a container which is what makes darker stove in usable is that i'm able to say this is davion build on top of that. Now we have some other thing and then on top of that then. Somewhere in there you can just take all the stuff that other people are building that's much simpler and say add my little specific things add my more details and make it more beautiful so at the end really you just have to say look at my beautiful finish product but you're leveraging like. Thousands of thousands of lines of code the other people. It's open to actually run your container you just. On your computer it's where you would run it first just. Just make sure it works you can install docker on your computer. Then open the console build damage and run it and it would run exactly the same as it didn't rstudio but now you can do that in a computer that doesn't have our install. It's a what's left. You've done all of this work you've put your thing in a docker container engineering departments are really impressed devops is like i understand what you're doing now and they take are seriously. Therapeutic that you have to think about you have to think about how can you encrypt your api to make it super secure how can you add logging so that way devops is happy with you how can you write unit tests to prove that your code is working and not absolutely broken and is returning as expected. Another thing is if you want to talk about those three things i can talk about them to you forever like forever and ever and ever and ever my background software engineering and this is really all we do at the end of the day. I think you need to release your code which just means put it out into the world that way people get to play with it. I know we do that at t-mobile as we have a very complicated software engineering pipeline. So when you check something into bitbucket which is like our github paycheck something in a fella named jenkins build damage for you which is just going through this dockerfile steps in setting up the machine just like you act. Animarathon which is like cheap kubernetes does the does the release so it puts it out somewhere on to the internet. And then made those just host the container so that's the website where would actually live. But you guys don't have time for that. That's that's a lot that's a lot of engineering. So you can just do it. There's a thing called elastic container store and elastic container repository italy. And if you just go to aws you can say here's my documents they will build it for you and they will host just that image it will automatically get more research sources whenever you need it took a ton of people are hitting your in point it'll say okay let's make this bigger and if nobody ever uses. Super super great. And so this really works this is a doctor like this is exactly how we productionize this for our consulting firms websites to right now you could go to pets. no less llc.com name and it will return you the stuff that jacksonville yesterday exactly the stuff that we went through. Please don't hit it all at once because we don't have auto scaling on it because we are incredibly cheap but anybody at any point could go and use this and so i didn't mention it yesterday but when we first made the deep learning container that generated these pet names we shopped it around to a lot of shelters in the seattle area please it'll be so funny. We really don't care about the fancy technology that you've applied. But if you know what shelter who wants to name their their animals from deep learning names we have a thing that you can have any point and sell our project for us anybody can use it for free if you name your pet after any of these names generated by a girl that work i will give you. A whole dollar. It really works it's super cool i love it. And so the takeaways are that. The stuff that engineers talked about its being so complicated really isn't. And. Working on. The first project at t-mobile where we really had data scientist and engineers a machine-learning people on the room side by side. It taught us that the disparities between the two disciplines are actually very small. And so if you guys can build a really complicated model with you all can you can absolutely add logging it's one line of code you can create an api it's three lines of code. You can deploy an api doctors really just writing down the steps that you already do every single time that you install something on your laptop so this is stuff that you can do to stop letting engineering people take away your work unless you find this terribly boring. You don't have to let engineers take away your work even levenger companies engineering department you can just throw it up on aws and it it all that's out the same. There was a thank you for sitting and listening to me tell you about how much i love doctor again if you want to talk about any of this for any length of time i absolutely want to. Double extra thank you to my son who allowed both of his mom's to be here today instead of hanging out with him especially his mother's day weekend and then the code is available on github for the whole thing so jacqueline's neural network down to dockerizing it is all available on the noelis llc. And you can follow me on twitter at heathercliff they talked about engineering. Thank you. \n"
     ]
    }
   ],
   "source": [
    "path = \"cO3QvioMESo.wav\"\n",
    "text = get_large_audio_transcription(path)\n",
    "print(\"\\nFull text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreya Gokhe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('5f6d3585eebd3cf2661bd617')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import gridfs\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.test_database  # use a database called \"test_database\"\n",
    "collection = db.files   # and inside that DB, a collection called \"files\"\n",
    "\n",
    "f = open('converted.txt')  # open a file\n",
    "text = f.read()    # read the entire contents, should be UTF-8 text\n",
    "\n",
    "# build a document to be inserted\n",
    "text_file_doc = {\"file_name\": \"converted.txt\", \"contents\" : text }\n",
    "# insert the contents into the \"file\" collection\n",
    "collection.insert(text_file_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF algorithm from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-55f2d584fe9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# NLTK function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtotal_documents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sent_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text) # NLTK function\n",
    "total_documents = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fa702ef74d69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# 8 Find the threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_find_average_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;31m#print(threshold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-cd7d515f205f>\u001b[0m in \u001b[0;36m_find_average_score\u001b[1;34m(sentenceValue)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Average value of a sentence from original summary_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msumValues\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords    \n",
    "    \n",
    "'''\n",
    "We already have a sentence tokenizer, so we just need \n",
    "to run the sent_tokenize() method to create the array of sentences.\n",
    "'''\n",
    "# 1 Sentence Tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "total_documents = len(sentences)\n",
    "#print(sentences)\n",
    "\n",
    "# 2 Create the Frequency matrix of the words in each sentence.\n",
    "freq_matrix = _create_frequency_matrix(sentences)\n",
    "#print(freq_matrix)\n",
    "\n",
    "'''\n",
    "Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
    "'''\n",
    "# 3 Calculate TermFrequency and generate a matrix\n",
    "tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "#print(tf_matrix)\n",
    "\n",
    "# 4 creating table for documents per words\n",
    "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "#print(count_doc_per_words)\n",
    "\n",
    "'''\n",
    "Inverse document frequency (IDF) is how unique or rare a word is.\n",
    "'''\n",
    "# 5 Calculate IDF and generate a matrix\n",
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "#print(idf_matrix)\n",
    "\n",
    "# 6 Calculate TF-IDF and generate a matrix\n",
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "#print(tf_idf_matrix)\n",
    "\n",
    "# 7 Important Algorithm: score the sentences\n",
    "sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#print(sentence_scores)\n",
    "\n",
    "# 8 Find the threshold\n",
    "threshold = _find_average_score(sentence_scores)\n",
    "#print(threshold)\n",
    "\n",
    "# 9 Important Algorithm: Generate the summary\n",
    "summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using  cosine similarity method of NLTK\n",
    "#### cosine similarity: used to determine how similar the documents are irrespective of their size.\n",
    "#### Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. In this context, the two vectors are arrays containing the word counts of two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords      #Stopwords are the English words which does not add much meaning to a sentence.\n",
    "from nltk.cluster.util import cosine_distance \n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx        #NetworkX is a Python library for studying graphs and networks\n",
    " \n",
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "    fh = open(\"summary.txt\", \"w+\")\n",
    "    \n",
    "    # Step 1 - Read text and split it\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank_numpy(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "        fh.write(str(summarize_text).strip('[').strip(']'))\n",
    "    # Step 5 - Ofcourse, output the summarize text\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Heather noelis and I was the first machine learning engineer hired to be on the AIT mat\n",
      "T-Mobile\n",
      "can I talk to you a little bit about how we actually use are in production at T-Mobile in the steps that you can do to do it as well because I know that nobody loves handing off their beautiful code to somebody else to just rewrite in Python\n",
      "and so what do we actually do our goal is not to build a chatbot when you hear lots of organizations talk about doing natural language processing in real time you think chatbots\n",
      "pergolas to essentially build a tool that the customer can interact or that the agent can interact with to help customers\n",
      "so I have a little screenshot of a sample of a tool that we have that\n",
      "if somebody says hello I'm traveling to Europe and I need to make sure my phone works when you run it through an intent model we say you're talking about unlocked so let's go get some account information about this individual that the agent will need to help you and then let's do an information retrieval and see internal Wikipedia articles that the agent can look at the services customer really quickly so the goal here is not again to build chatbots and put something in front of the user\n",
      "it's to build tools that actually help the agent help you faster\n",
      "and so I said I'm going to talk about putting our introduction but what does that actually mean it's basically whenever you're sitting on your computer you're working at rmarkdown file you're doing an analysis you run your code wants to get the result\n",
      "then you build it and that's cool that's continuously running anybody can come up to your laptop at any time and see that that code is running\n",
      "I'm putting into production means putting it somewhere that's outside of your laptop where it lives all the time and that users can always interact with it's always on it's always running\n",
      "and so I'm piggybacking off of Jacqueline's presentation yesterday we're going to take the pet name generator the big tensorflow deep learning model that she created and we are going to put it into production in my talk so if she handed me this code what are the things that I would have to do to make it actually run scalable at T-Mobile\n",
      "I thought we do this with apis and people say API all the time and it sounds really intimidating but all in API is if every time that you go to a website on your phone you are hitting an API\n",
      "an API is just a way of getting information from the internet instead of from a console so you guys have apis all the time and are two ways that people primarily hit apis every time that you go to a website that's a get request you're saying\n",
      "weather.com please tell me\n",
      "what\n",
      "information I want to see like I want to get the weather of the day\n",
      "or you can do a\n",
      "post request which would just be like\n",
      "I want to add my name to your website I want to sign up for a mailing list so here's my name website and do whatever you want with it\n",
      "and so a get request is just going to a website or getting any information from the internet and so for us what that means is that we need to convert the variables that it sends to us so I can use it\n",
      "we need to make a prediction on those variables in return the results and that's it so if you remember yesterday where we left off with Jacquelyn she'd created a nice function that was just to return to bunch of predictions\n",
      "so in this case I would say I want to get 20 pet names\n",
      "and then the model would run in generate 25 names and then would give it back to me\n",
      "that's all in Apison engineer say and they talk really lofty they're all lying to you it's not that complicated\n",
      "and we do that with plumber which is a package developed by our studio that is literally the easiest thing in the entire world\n",
      "so it is I'm not kidding it takes these three lines of code and that's all it takes\n",
      "to make what Jacqueline put on the screen yesterday into an API\n",
      "so all you have to do is import plumber\n",
      "show Plumber where the endpoints are in a limb points are our what comes after the / okay went to weather.com Seattle the endpoint is Seattle part of the URL\n",
      "what are the things after the slash\n",
      "open a port to the internet which means that anybody can talk to you import Plummer and you've done it you've built an API so when engineers make the sound really complicated\n",
      "it's three lines of R code anybody here can do it\n",
      "like I said you first you just create a file for the endpoint so if you look here\n",
      "it just says I'm going to use a get function and I want to get names\n",
      "return the this is exactly the function that Jacqueline date yesterday to just return many names 20 names that we do the import and then you go to the website on your computer\n",
      "and it returns a result\n",
      "boots like\n",
      "incredibly easy\n",
      "you just run your function\n",
      "go to the actual Port that you open to the internet and then you feel super powerful cuz you did a thing that Engineers bragged about doing and say that you can't do in our all the time but\n",
      "6 lines of code\n",
      "I build Java services in this is way easier\n",
      "and we really love plumber like\n",
      "I always say that shine your plumber should really be like\n",
      "I should be giving him an award because they're paying for my house at the\n",
      "it's a really really demonstrate that I have a totally unprompted\n",
      "sample of my son he was 16 months old at the time\n",
      "he always ask me what's on my laptop and so here's an example of how much in my family we love plumber\n",
      "Amber\n",
      "who is this\n",
      "plumber yea\n",
      "I thought my 16 month old child who only knows like slide in Agua also knows what plumber is because that's how important plumber is to me\n",
      "I thought you felt it lives on your laptop you have an API and hit a senior API sucks\n",
      "because you have to be your laptop have to be connected to the internet you have to be running your code and you have to just have it there waiting for them\n",
      "nobody wants to live their life like that just having their laptop waiting for some\n",
      "probably jerk to be like can I please access your model so we're going to put it in the cloud which is again another thing that Engineers say\n",
      "what does it mean\n",
      "it's over all the parties are giant laptops in the sky that somebody else owns\n",
      "and it's literally it's so if you have it on your laptop sitting there you didn't put it on somebody else's laptop you know all the stuff\n",
      "what we need for our API that Jack built to work we just need an operating system the correct version of are all of the libraries that you think that you need\n",
      "what you just wrote those three little lines of code and everything exactly should you yesterday and then just open a port to the internet\n",
      "and so we've already done that on our laptops to let's talk about how we would do that in the cloud\n",
      "it would be exactly the same you would install rstudio you would go through the exact same stuff that Jacqueline did yesterday and you would do my last two slides\n",
      "super super easy to do on a virtual machine which is somebody else's Sky laptop\n",
      "the downsides of using a virtual machine is laptops are expensive right like every time that you get a new laptop and you have to set it up it takes quite a bit of time to do that the companies paying you that time to like reset up the sky laptops\n",
      "it takes a lot of time the setup is probably undocumented I have a file at like all the special things when I get a new computer that I want to put on my computer but I do know you probably have to install a bunch of weird JavaScript plugins all the time and then you forget that you use this one packaging you have to reinstall everything so that's all undocumented so if you were to leave the company\n",
      "they couldn't recreate your computer if somebody turned off your Sky computer they couldn't recreate it\n",
      "and so since good engineering is repeatable\n",
      "that probably isn't good engineering to just set up a virtual\n",
      "so what can we do that is\n",
      "super super repeatable\n",
      "how can we document this\n",
      "and that's all containers are people talk about containers they talk about docker\n",
      "containers are cheaper there is less computational overhead cuz you don't need to use a whole computer every time there's super trendy so people think that you're doing really cutting-edge technology when you talk about it they're made to crash and be restarted so every time that you restart your computer it takes forever to restart a Docker container\n",
      "and then scaling and coordinating is easy so I can say this Docker container is out there living but I started up this one until just redirect rap\n",
      "so I can just my old models hear my new models here let's just\n",
      "which words\n",
      "pointing and that's all kubernetes is if anyone's ever thrown that word that you do is just how do we tell which container reporting at again not super complicated\n",
      "dark and heavy\n",
      "all that doctor is is the repeatable steps that you need to setup a virtual machine the repeatable steps were if I was to give you a laptop and say write down everything that you need to run my API under machine we just write it so computer can do that so we don't have to have people sitting there forever well\n",
      "rstudio downloads for the 89th time because I'm really bad at building models and I need to be deployed 89 times before one works\n",
      "is there a what this means that you can run docker\n",
      "Encore you can bring your our code on computers that don't have are installed\n",
      "because you installed in the container and the container look on the computer\n",
      "so you can take it to your mom's house be like Mom run this really cool code on your computer and you don't remind her through all the ridiculous set-up steps\n",
      "at the end of the day I choose kind of like a little steps and they don't care about what you're actually doing they just want it to work\n",
      "kid doctor goes ahead and takes care of all of that for you never have to worry about if you install a certain our package doesn't break somebody else's code cuz he put it in a nice little container that contains it and keeps it from breaking everybody else's stuff that's really where the name comes from\n",
      "but what does that look like\n",
      "so we have a dockerfile and like I said that's just a list of instructions that would be used to set up your computer at any time\n",
      "do you have the image which is after somebody builds that dockerfile and sets up the computer like you want that's the image and when you run it that's the container so people will throw these words that you will not but they're all really the same things just in different forms of the process\n",
      "now I need my prop\n",
      "thank you\n",
      "it's a Disney pet names dockerfile for the API\n",
      "Jackson building her talk yesterday\n",
      "it's okay just have a starting image which we use rocker which is just an R Docker image\n",
      "and then there's some Lenox libraries we have to import python because carrots runs on python let me copy over our scripts install are libraries open up the port and then just say run the main function\n",
      "but there's a trick when you look at this\n",
      "the first thing that it says is rocker version\n",
      "three-point whatever\n",
      "but what does that look like\n",
      "well that's a lot of fun and it actually it's if it's a lot a lot of code it's a good way to think about Docker images\n",
      "is to think about nesting dolls so the first image that I showed you\n",
      "this is kind of your finished product\n",
      "but that front line and kind of open it up\n",
      "is it okay okay so it's built on something simpler somebody else with a lot of words to this is the next event you say okay\n",
      "sure but that also has an import line it's from Davion which is an operating system\n",
      "so you can look at it Nike okay so now we have a level smaller even\n",
      "what's this\n",
      "there's another one\n",
      "so you got to open at night okay so finally finally we reached the end\n",
      "isn't this is what you're doing every time that you make a container which is what makes darker stove in usable is that I'm able to say this is Davion build on top of that\n",
      "now we have some other thing and then on top of that then\n",
      "somewhere in there you can just take all the stuff that other people are building that's much simpler and say add my little specific things add my more details and make it more beautiful so at the end really you just have to say look at my beautiful finish product but you're leveraging like\n",
      "thousands of thousands of lines of code the other people\n",
      "it's open to actually run your container you just\n",
      "on your computer it's where you would run it first just\n",
      "just make sure it works you can install Docker on your computer\n",
      "then open the console build damage and run it and it would run exactly the same as it didn't rstudio but now you can do that in a computer that doesn't have our install\n",
      "it's a what's left\n",
      "you've done all of this work you've put your thing in a Docker container engineering departments are really impressed devops is like I understand what you're doing now and they take are seriously\n",
      "therapeutic that you have to think about you have to think about how can you encrypt your API to make it super secure how can you add logging so that way devops is happy with you how can you write unit tests to prove that your code is working and not absolutely broken and is returning as expected\n",
      "another thing is if you want to talk about those three things I can talk about them to you forever like forever and ever and ever and ever my background software engineering and this is really all we do at the end of the day\n",
      "I think you need to release your code which just means put it out into the world that way people get to play with it\n",
      "I know we do that at T-Mobile as we have a very complicated software engineering pipeline\n",
      "so when you check something into bitbucket which is like our GitHub paycheck something in a fella named Jenkins build damage for you which is just going through this dockerfile steps in setting up the machine just like you act\n",
      "animarathon which is like cheap kubernetes does the does the release so it puts it out somewhere on to the internet\n",
      "and then made those just host the container so that's the website where would actually live\n",
      "but you guys don't have time for that\n",
      "that's that's a lot that's a lot of engineering\n",
      "so you can just do it\n",
      "there's a thing called elastic Container Store and elastic container repository Italy\n",
      "and if you just go to AWS you can say here's my documents they will build it for you and they will host just that image it will automatically get more research sources whenever you need it took a ton of people are hitting your in point it'll say okay let's make this bigger and if nobody ever uses\n",
      "super super great\n",
      "and so this really works this is a doctor like this is exactly how we productionize this for our consulting firms websites to right now you could go to pets\n",
      "No less llc.com name and it will return you the stuff that Jacksonville yesterday exactly the stuff that we went through\n",
      "please don't hit it all at once because we don't have Auto scaling on it because we are incredibly cheap but anybody at any point could go and use this and so I didn't mention it yesterday but when we first made the Deep learning container that generated these pet names we shopped it around to a lot of shelters in the Seattle area please it'll be so funny\n",
      "we really don't care about the fancy technology that you've applied\n",
      "but if you know what shelter who wants to name their their animals from Deep learning names we have a thing that you can have any point and sell our project for us anybody can use it for free if you name your pet after any of these names generated by a girl that work I will give you\n",
      "a whole dollar\n",
      "it really works it's super cool I love it\n",
      "and so the takeaways are that\n",
      "the stuff that Engineers talked about its being so complicated really isn't\n",
      "and\n",
      "working on\n",
      "the first project at T-Mobile where we really had data scientist and Engineers a machine-learning people on the room side by side\n",
      "it taught us that the disparities between the two disciplines are actually very small\n",
      "and so if you guys can build a really complicated model with you all can you can absolutely add logging it's one line of code you can create an API it's three lines of code\n",
      "you can deploy an API doctors really just writing down the steps that you already do every single time that you install something on your laptop so this is stuff that you can do to stop letting engineering people take away your work unless you find this terribly boring\n",
      "you don't have to let Engineers take away your work even levenger companies engineering department you can just throw it up on AWS and it it all that's out the same\n",
      "there was a thank you for sitting and listening to me tell you about how much I love doctor again if you want to talk about any of this for any length of time I absolutely want to\n",
      "double extra thank you to my son who allowed both of his mom's to be here today instead of hanging out with him especially his Mother's Day weekend and then the code is available on GitHub for the whole thing so Jacqueline's neural network down to dockerizing it is all available on the noelis LLC\n",
      "and you can follow me on Twitter at heathercliff they talked about engineering\n",
      "thank you\n",
      "\n",
      "Indexes of top ranked_sentence order are  [(0.015529441529635918, ['do', 'you', 'have', 'the', 'image', 'which', 'is', 'after', 'somebody', 'builds', 'that', 'dockerfile', 'and', 'sets', 'up', 'the', 'computer', 'like', 'you', 'want', \"that's\", 'the', 'image', 'and', 'when', 'you', 'run', 'it', \"that's\", 'the', 'container', 'so', 'people', 'will', 'throw', 'these', 'words', 'that', 'you', 'will', 'not', 'but', \"they're\", 'all', 'really', 'the', 'same', 'things', 'just', 'in', 'different', 'forms', 'of', 'the', 'process']), (0.013589181887125993, ['containers', 'are', 'cheaper', 'there', 'is', 'less', 'computational', 'overhead', 'cuz', 'you', \"don't\", 'need', 'to', 'use', 'a', 'whole', 'computer', 'every', 'time', \"there's\", 'super', 'trendy', 'so', 'people', 'think', 'that', \"you're\", 'doing', 'really', 'cutting-edge', 'technology', 'when', 'you', 'talk', 'about', 'it', \"they're\", 'made', 'to', 'crash', 'and', 'be', 'restarted', 'so', 'every', 'time', 'that', 'you', 'restart', 'your', 'computer', 'it', 'takes', 'forever', 'to', 'restart', 'a', 'Docker', 'container']), (0.013379467737083118, ['and', 'we', 'really', 'love', 'plumber', 'like']), (0.01312588250531965, ['I', 'always', 'say', 'that', 'shine', 'your', 'plumber', 'should', 'really', 'be', 'like']), (0.012831365937113386, ['and', 'so', 'I', 'said', \"I'm\", 'going', 'to', 'talk', 'about', 'putting', 'our', 'introduction', 'but', 'what', 'does', 'that', 'actually', 'mean', \"it's\", 'basically', 'whenever', \"you're\", 'sitting', 'on', 'your', 'computer', \"you're\", 'working', 'at', 'rmarkdown', 'file', \"you're\", 'doing', 'an', 'analysis', 'you', 'run', 'your', 'code', 'wants', 'to', 'get', 'the', 'result']), (0.012580889149606833, ['so', 'you', 'can', 'take', 'it', 'to', 'your', \"mom's\", 'house', 'be', 'like', 'Mom', 'run', 'this', 'really', 'cool', 'code', 'on', 'your', 'computer', 'and', 'you', \"don't\", 'remind', 'her', 'through', 'all', 'the', 'ridiculous', 'set-up', 'steps']), (0.012497937723526472, ['somewhere', 'in', 'there', 'you', 'can', 'just', 'take', 'all', 'the', 'stuff', 'that', 'other', 'people', 'are', 'building', \"that's\", 'much', 'simpler', 'and', 'say', 'add', 'my', 'little', 'specific', 'things', 'add', 'my', 'more', 'details', 'and', 'make', 'it', 'more', 'beautiful', 'so', 'at', 'the', 'end', 'really', 'you', 'just', 'have', 'to', 'say', 'look', 'at', 'my', 'beautiful', 'finish', 'product', 'but', \"you're\", 'leveraging', 'like']), (0.012453449316157892, ['so', 'we', 'have', 'a', 'dockerfile', 'and', 'like', 'I', 'said', \"that's\", 'just', 'a', 'list', 'of', 'instructions', 'that', 'would', 'be', 'used', 'to', 'set', 'up', 'your', 'computer', 'at', 'any', 'time']), (0.012243309031603419, ['it', 'takes', 'a', 'lot', 'of', 'time', 'the', 'setup', 'is', 'probably', 'undocumented', 'I', 'have', 'a', 'file', 'at', 'like', 'all', 'the', 'special', 'things', 'when', 'I', 'get', 'a', 'new', 'computer', 'that', 'I', 'want', 'to', 'put', 'on', 'my', 'computer', 'but', 'I', 'do', 'know', 'you', 'probably', 'have', 'to', 'install', 'a', 'bunch', 'of', 'weird', 'JavaScript', 'plugins', 'all', 'the', 'time', 'and', 'then', 'you', 'forget', 'that', 'you', 'use', 'this', 'one', 'packaging', 'you', 'have', 'to', 'reinstall', 'everything', 'so', \"that's\", 'all', 'undocumented', 'so', 'if', 'you', 'were', 'to', 'leave', 'the', 'company']), (0.012173364807116154, ['and', 'so', 'if', 'you', 'guys', 'can', 'build', 'a', 'really', 'complicated', 'model', 'with', 'you', 'all', 'can', 'you', 'can', 'absolutely', 'add', 'logging', \"it's\", 'one', 'line', 'of', 'code', 'you', 'can', 'create', 'an', 'API', \"it's\", 'three', 'lines', 'of', 'code']), (0.012153778337059072, [\"you've\", 'done', 'all', 'of', 'this', 'work', \"you've\", 'put', 'your', 'thing', 'in', 'a', 'Docker', 'container', 'engineering', 'departments', 'are', 'really', 'impressed', 'devops', 'is', 'like', 'I', 'understand', 'what', \"you're\", 'doing', 'now', 'and', 'they', 'take', 'are', 'seriously']), (0.011662798686345458, ['the', 'downsides', 'of', 'using', 'a', 'virtual', 'machine', 'is', 'laptops', 'are', 'expensive', 'right', 'like', 'every', 'time', 'that', 'you', 'get', 'a', 'new', 'laptop', 'and', 'you', 'have', 'to', 'set', 'it', 'up', 'it', 'takes', 'quite', 'a', 'bit', 'of', 'time', 'to', 'do', 'that', 'the', 'companies', 'paying', 'you', 'that', 'time', 'to', 'like', 'reset', 'up', 'the', 'sky', 'laptops']), (0.011555447621719199, ['and', 'so', \"I'm\", 'piggybacking', 'off', 'of', \"Jacqueline's\", 'presentation', 'yesterday', \"we're\", 'going', 'to', 'take', 'the', 'pet', 'name', 'generator', 'the', 'big', 'tensorflow', 'deep', 'learning', 'model', 'that', 'she', 'created', 'and', 'we', 'are', 'going', 'to', 'put', 'it', 'into', 'production', 'in', 'my', 'talk', 'so', 'if', 'she', 'handed', 'me', 'this', 'code', 'what', 'are', 'the', 'things', 'that', 'I', 'would', 'have', 'to', 'do', 'to', 'make', 'it', 'actually', 'run', 'scalable', 'at', 'T-Mobile']), (0.011298232775198641, ['if', 'somebody', 'says', 'hello', \"I'm\", 'traveling', 'to', 'Europe', 'and', 'I', 'need', 'to', 'make', 'sure', 'my', 'phone', 'works', 'when', 'you', 'run', 'it', 'through', 'an', 'intent', 'model', 'we', 'say', \"you're\", 'talking', 'about', 'unlocked', 'so', \"let's\", 'go', 'get', 'some', 'account', 'information', 'about', 'this', 'individual', 'that', 'the', 'agent', 'will', 'need', 'to', 'help', 'you', 'and', 'then', \"let's\", 'do', 'an', 'information', 'retrieval', 'and', 'see', 'internal', 'Wikipedia', 'articles', 'that', 'the', 'agent', 'can', 'look', 'at', 'the', 'services', 'customer', 'really', 'quickly', 'so', 'the', 'goal', 'here', 'is', 'not', 'again', 'to', 'build', 'chatbots', 'and', 'put', 'something', 'in', 'front', 'of', 'the', 'user']), (0.011044289632962494, ['I', 'thought', 'we', 'do', 'this', 'with', 'apis', 'and', 'people', 'say', 'API', 'all', 'the', 'time', 'and', 'it', 'sounds', 'really', 'intimidating', 'but', 'all', 'in', 'API', 'is', 'if', 'every', 'time', 'that', 'you', 'go', 'to', 'a', 'website', 'on', 'your', 'phone', 'you', 'are', 'hitting', 'an', 'API']), (0.010996921897309843, ['open', 'a', 'port', 'to', 'the', 'internet', 'which', 'means', 'that', 'anybody', 'can', 'talk', 'to', 'you', 'import', 'Plummer', 'and', \"you've\", 'done', 'it', \"you've\", 'built', 'an', 'API', 'so', 'when', 'engineers', 'make', 'the', 'sound', 'really', 'complicated']), (0.010996386652807123, ['another', 'thing', 'is', 'if', 'you', 'want', 'to', 'talk', 'about', 'those', 'three', 'things', 'I', 'can', 'talk', 'about', 'them', 'to', 'you', 'forever', 'like', 'forever', 'and', 'ever', 'and', 'ever', 'and', 'ever', 'my', 'background', 'software', 'engineering', 'and', 'this', 'is', 'really', 'all', 'we', 'do', 'at', 'the', 'end', 'of', 'the', 'day']), (0.010941464314515684, ['then', 'you', 'build', 'it', 'and', \"that's\", 'cool', \"that's\", 'continuously', 'running', 'anybody', 'can', 'come', 'up', 'to', 'your', 'laptop', 'at', 'any', 'time', 'and', 'see', 'that', 'that', 'code', 'is', 'running']), (0.010746294137366656, ['but', 'what', 'does', 'that', 'look', 'like']), (0.010746294137366656, ['but', 'what', 'does', 'that', 'look', 'like']), (0.010402140037102782, ['then', 'open', 'the', 'console', 'build', 'damage', 'and', 'run', 'it', 'and', 'it', 'would', 'run', 'exactly', 'the', 'same', 'as', 'it', \"didn't\", 'rstudio', 'but', 'now', 'you', 'can', 'do', 'that', 'in', 'a', 'computer', 'that', \"doesn't\", 'have', 'our', 'install']), (0.01032137828404103, ['all', 'that', 'doctor', 'is', 'is', 'the', 'repeatable', 'steps', 'that', 'you', 'need', 'to', 'setup', 'a', 'virtual', 'machine', 'the', 'repeatable', 'steps', 'were', 'if', 'I', 'was', 'to', 'give', 'you', 'a', 'laptop', 'and', 'say', 'write', 'down', 'everything', 'that', 'you', 'need', 'to', 'run', 'my', 'API', 'under', 'machine', 'we', 'just', 'write', 'it', 'so', 'computer', 'can', 'do', 'that', 'so', 'we', \"don't\", 'have', 'to', 'have', 'people', 'sitting', 'there', 'forever', 'well']), (0.010311834233757582, [\"that's\", 'all', 'in', 'Apison', 'engineer', 'say', 'and', 'they', 'talk', 'really', 'lofty', \"they're\", 'all', 'lying', 'to', 'you', \"it's\", 'not', 'that', 'complicated']), (0.010296173831040178, ['on', 'your', 'computer', \"it's\", 'where', 'you', 'would', 'run', 'it', 'first', 'just']), (0.01028680472437671, ['an', 'API', 'is', 'just', 'a', 'way', 'of', 'getting', 'information', 'from', 'the', 'internet', 'instead', 'of', 'from', 'a', 'console', 'so', 'you', 'guys', 'have', 'apis', 'all', 'the', 'time', 'and', 'are', 'two', 'ways', 'that', 'people', 'primarily', 'hit', 'apis', 'every', 'time', 'that', 'you', 'go', 'to', 'a', 'website', \"that's\", 'a', 'get', 'request', \"you're\", 'saying']), (0.0101336341850503, ['you', 'can', 'deploy', 'an', 'API', 'doctors', 'really', 'just', 'writing', 'down', 'the', 'steps', 'that', 'you', 'already', 'do', 'every', 'single', 'time', 'that', 'you', 'install', 'something', 'on', 'your', 'laptop', 'so', 'this', 'is', 'stuff', 'that', 'you', 'can', 'do', 'to', 'stop', 'letting', 'engineering', 'people', 'take', 'away', 'your', 'work', 'unless', 'you', 'find', 'this', 'terribly', 'boring']), (0.010011344133288013, ['at', 'the', 'end', 'of', 'the', 'day', 'I', 'choose', 'kind', 'of', 'like', 'a', 'little', 'steps', 'and', 'they', \"don't\", 'care', 'about', 'what', \"you're\", 'actually', 'doing', 'they', 'just', 'want', 'it', 'to', 'work']), (0.009969732632029698, ['kid', 'doctor', 'goes', 'ahead', 'and', 'takes', 'care', 'of', 'all', 'of', 'that', 'for', 'you', 'never', 'have', 'to', 'worry', 'about', 'if', 'you', 'install', 'a', 'certain', 'our', 'package', \"doesn't\", 'break', 'somebody', \"else's\", 'code', 'cuz', 'he', 'put', 'it', 'in', 'a', 'nice', 'little', 'container', 'that', 'contains', 'it', 'and', 'keeps', 'it', 'from', 'breaking', 'everybody', \"else's\", 'stuff', \"that's\", 'really', 'where', 'the', 'name', 'comes', 'from']), (0.009722492167697954, [\"it's\", 'open', 'to', 'actually', 'run', 'your', 'container', 'you', 'just']), (0.009715547348355202, ['probably', 'jerk', 'to', 'be', 'like', 'can', 'I', 'please', 'access', 'your', 'model', 'so', \"we're\", 'going', 'to', 'put', 'it', 'in', 'the', 'cloud', 'which', 'is', 'again', 'another', 'thing', 'that', 'Engineers', 'say']), (0.009597700969090614, ['go', 'to', 'the', 'actual', 'Port', 'that', 'you', 'open', 'to', 'the', 'internet', 'and', 'then', 'you', 'feel', 'super', 'powerful', 'cuz', 'you', 'did', 'a', 'thing', 'that', 'Engineers', 'bragged', 'about', 'doing', 'and', 'say', 'that', 'you', \"can't\", 'do', 'in', 'our', 'all', 'the', 'time', 'but']), (0.009556859444005734, ['I', 'think', 'you', 'need', 'to', 'release', 'your', 'code', 'which', 'just', 'means', 'put', 'it', 'out', 'into', 'the', 'world', 'that', 'way', 'people', 'get', 'to', 'play', 'with', 'it']), (0.009524379898411095, ['and', 'then', 'made', 'those', 'just', 'host', 'the', 'container', 'so', \"that's\", 'the', 'website', 'where', 'would', 'actually', 'live']), (0.009156243947470402, ['there', 'was', 'a', 'thank', 'you', 'for', 'sitting', 'and', 'listening', 'to', 'me', 'tell', 'you', 'about', 'how', 'much', 'I', 'love', 'doctor', 'again', 'if', 'you', 'want', 'to', 'talk', 'about', 'any', 'of', 'this', 'for', 'any', 'length', 'of', 'time', 'I', 'absolutely', 'want', 'to']), (0.009082592866486572, ['can', 'I', 'talk', 'to', 'you', 'a', 'little', 'bit', 'about', 'how', 'we', 'actually', 'use', 'are', 'in', 'production', 'at', 'T-Mobile', 'in', 'the', 'steps', 'that', 'you', 'can', 'do', 'to', 'do', 'it', 'as', 'well', 'because', 'I', 'know', 'that', 'nobody', 'loves', 'handing', 'off', 'their', 'beautiful', 'code', 'to', 'somebody', 'else', 'to', 'just', 'rewrite', 'in', 'Python']), (0.00903300468147446, [\"isn't\", 'this', 'is', 'what', \"you're\", 'doing', 'every', 'time', 'that', 'you', 'make', 'a', 'container', 'which', 'is', 'what', 'makes', 'darker', 'stove', 'in', 'usable', 'is', 'that', \"I'm\", 'able', 'to', 'say', 'this', 'is', 'Davion', 'build', 'on', 'top', 'of', 'that']), (0.008982838541112294, ['what', 'you', 'just', 'wrote', 'those', 'three', 'little', 'lines', 'of', 'code', 'and', 'everything', 'exactly', 'should', 'you', 'yesterday', 'and', 'then', 'just', 'open', 'a', 'port', 'to', 'the', 'internet']), (0.008888428230811964, ['and', 'if', 'you', 'just', 'go', 'to', 'AWS', 'you', 'can', 'say', \"here's\", 'my', 'documents', 'they', 'will', 'build', 'it', 'for', 'you', 'and', 'they', 'will', 'host', 'just', 'that', 'image', 'it', 'will', 'automatically', 'get', 'more', 'research', 'sources', 'whenever', 'you', 'need', 'it', 'took', 'a', 'ton', 'of', 'people', 'are', 'hitting', 'your', 'in', 'point', \"it'll\", 'say', 'okay', \"let's\", 'make', 'this', 'bigger', 'and', 'if', 'nobody', 'ever', 'uses']), (0.008888236657285017, ['so', 'in', 'this', 'case', 'I', 'would', 'say', 'I', 'want', 'to', 'get', '20', 'pet', 'names']), (0.008845695303177168, ['post', 'request', 'which', 'would', 'just', 'be', 'like']), (0.008637557952377766, ['well', \"that's\", 'a', 'lot', 'of', 'fun', 'and', 'it', 'actually', \"it's\", 'if', \"it's\", 'a', 'lot', 'a', 'lot', 'of', 'code', \"it's\", 'a', 'good', 'way', 'to', 'think', 'about', 'Docker', 'images']), (0.008605453368873604, ['information', 'I', 'want', 'to', 'see', 'like', 'I', 'want', 'to', 'get', 'the', 'weather', 'of', 'the', 'day']), (0.008603991288796022, ['rstudio', 'downloads', 'for', 'the', '89th', 'time', 'because', \"I'm\", 'really', 'bad', 'at', 'building', 'models', 'and', 'I', 'need', 'to', 'be', 'deployed', '89', 'times', 'before', 'one', 'works']), (0.008507681878343228, ['it', 'really', 'works', \"it's\", 'super', 'cool', 'I', 'love', 'it']), (0.008503374908494638, ['like', 'I', 'said', 'you', 'first', 'you', 'just', 'create', 'a', 'file', 'for', 'the', 'endpoint', 'so', 'if', 'you', 'look', 'here']), (0.008328725485448604, ['so', 'it', 'is', \"I'm\", 'not', 'kidding', 'it', 'takes', 'these', 'three', 'lines', 'of', 'code', 'and', \"that's\", 'all', 'it', 'takes']), (0.008244417552940702, ['super', 'super', 'easy', 'to', 'do', 'on', 'a', 'virtual', 'machine', 'which', 'is', 'somebody', \"else's\", 'Sky', 'laptop']), (0.008242777347460024, ['because', 'you', 'installed', 'in', 'the', 'container', 'and', 'the', 'container', 'look', 'on', 'the', 'computer']), (0.008150155007273686, ['and', 'so', 'this', 'really', 'works', 'this', 'is', 'a', 'doctor', 'like', 'this', 'is', 'exactly', 'how', 'we', 'productionize', 'this', 'for', 'our', 'consulting', 'firms', 'websites', 'to', 'right', 'now', 'you', 'could', 'go', 'to', 'pets']), (0.00813975723342426, [\"that's\", \"that's\", 'a', 'lot', \"that's\", 'a', 'lot', 'of', 'engineering']), (0.00812675373747195, ['I', 'thought', 'my', '16', 'month', 'old', 'child', 'who', 'only', 'knows', 'like', 'slide', 'in', 'Agua', 'also', 'knows', 'what', 'plumber', 'is', 'because', \"that's\", 'how', 'important', 'plumber', 'is', 'to', 'me']), (0.00801581006474432, ['so', 'when', 'you', 'check', 'something', 'into', 'bitbucket', 'which', 'is', 'like', 'our', 'GitHub', 'paycheck', 'something', 'in', 'a', 'fella', 'named', 'Jenkins', 'build', 'damage', 'for', 'you', 'which', 'is', 'just', 'going', 'through', 'this', 'dockerfile', 'steps', 'in', 'setting', 'up', 'the', 'machine', 'just', 'like', 'you', 'act']), (0.00798739454784958, ['boots', 'like']), (0.007945500392554844, ['it', 'just', 'says', \"I'm\", 'going', 'to', 'use', 'a', 'get', 'function', 'and', 'I', 'want', 'to', 'get', 'names']), (0.0078372660490532, ['the', 'stuff', 'that', 'Engineers', 'talked', 'about', 'its', 'being', 'so', 'complicated', 'really', \"isn't\"]), (0.007814494632388874, ['and', \"that's\", 'all', 'containers', 'are', 'people', 'talk', 'about', 'containers', 'they', 'talk', 'about', 'docker']), (0.007756347144639724, ['therapeutic', 'that', 'you', 'have', 'to', 'think', 'about', 'you', 'have', 'to', 'think', 'about', 'how', 'can', 'you', 'encrypt', 'your', 'API', 'to', 'make', 'it', 'super', 'secure', 'how', 'can', 'you', 'add', 'logging', 'so', 'that', 'way', 'devops', 'is', 'happy', 'with', 'you', 'how', 'can', 'you', 'write', 'unit', 'tests', 'to', 'prove', 'that', 'your', 'code', 'is', 'working', 'and', 'not', 'absolutely', 'broken', 'and', 'is', 'returning', 'as', 'expected']), (0.0075854021776441925, ['pointing', 'and', \"that's\", 'all', 'kubernetes', 'is', 'if', \"anyone's\", 'ever', 'thrown', 'that', 'word', 'that', 'you', 'do', 'is', 'just', 'how', 'do', 'we', 'tell', 'which', 'container', 'reporting', 'at', 'again', 'not', 'super', 'complicated']), (0.007548350381344112, ['please', \"don't\", 'hit', 'it', 'all', 'at', 'once', 'because', 'we', \"don't\", 'have', 'Auto', 'scaling', 'on', 'it', 'because', 'we', 'are', 'incredibly', 'cheap', 'but', 'anybody', 'at', 'any', 'point', 'could', 'go', 'and', 'use', 'this', 'and', 'so', 'I', \"didn't\", 'mention', 'it', 'yesterday', 'but', 'when', 'we', 'first', 'made', 'the', 'Deep', 'learning', 'container', 'that', 'generated', 'these', 'pet', 'names', 'we', 'shopped', 'it', 'around', 'to', 'a', 'lot', 'of', 'shelters', 'in', 'the', 'Seattle', 'area', 'please', \"it'll\", 'be', 'so', 'funny']), (0.007521711609702543, ['return', 'the', 'this', 'is', 'exactly', 'the', 'function', 'that', 'Jacqueline', 'date', 'yesterday', 'to', 'just', 'return', 'many', 'names', '20', 'names', 'that', 'we', 'do', 'the', 'import', 'and', 'then', 'you', 'go', 'to', 'the', 'website', 'on', 'your', 'computer']), (0.007332277889716642, ['it', 'would', 'be', 'exactly', 'the', 'same', 'you', 'would', 'install', 'rstudio', 'you', 'would', 'go', 'through', 'the', 'exact', 'same', 'stuff', 'that', 'Jacqueline', 'did', 'yesterday', 'and', 'you', 'would', 'do', 'my', 'last', 'two', 'slides']), (0.007316364682973106, ['nobody', 'wants', 'to', 'live', 'their', 'life', 'like', 'that', 'just', 'having', 'their', 'laptop', 'waiting', 'for', 'some']), (0.007205491469492915, [\"I'm\", 'putting', 'into', 'production', 'means', 'putting', 'it', 'somewhere', \"that's\", 'outside', 'of', 'your', 'laptop', 'where', 'it', 'lives', 'all', 'the', 'time', 'and', 'that', 'users', 'can', 'always', 'interact', 'with', \"it's\", 'always', 'on', \"it's\", 'always', 'running']), (0.007150628516697688, ['because', 'you', 'have', 'to', 'be', 'your', 'laptop', 'have', 'to', 'be', 'connected', 'to', 'the', 'internet', 'you', 'have', 'to', 'be', 'running', 'your', 'code', 'and', 'you', 'have', 'to', 'just', 'have', 'it', 'there', 'waiting', 'for', 'them']), (0.007137149928398092, ['just', 'make', 'sure', 'it', 'works', 'you', 'can', 'install', 'Docker', 'on', 'your', 'computer']), (0.007057090376822358, ['and', 'so', 'what', 'do', 'we', 'actually', 'do', 'our', 'goal', 'is', 'not', 'to', 'build', 'a', 'chatbot', 'when', 'you', 'hear', 'lots', 'of', 'organizations', 'talk', 'about', 'doing', 'natural', 'language', 'processing', 'in', 'real', 'time', 'you', 'think', 'chatbots']), (0.0070323710438513955, ['and', 'then', 'the', 'model', 'would', 'run', 'in', 'generate', '25', 'names', 'and', 'then', 'would', 'give', 'it', 'back', 'to', 'me']), (0.006905180401767281, ['and', \"it's\", 'literally', \"it's\", 'so', 'if', 'you', 'have', 'it', 'on', 'your', 'laptop', 'sitting', 'there', 'you', \"didn't\", 'put', 'it', 'on', 'somebody', \"else's\", 'laptop', 'you', 'know', 'all', 'the', 'stuff']), (0.006896094019285038, ['he', 'always', 'ask', 'me', \"what's\", 'on', 'my', 'laptop', 'and', 'so', \"here's\", 'an', 'example', 'of', 'how', 'much', 'in', 'my', 'family', 'we', 'love', 'plumber']), (0.0068412988363234775, [\"it's\", 'a', 'really', 'really', 'demonstrate', 'that', 'I', 'have', 'a', 'totally', 'unprompted']), (0.006788124697184563, [\"it's\", 'three', 'lines', 'of', 'R', 'code', 'anybody', 'here', 'can', 'do', 'it']), (0.006659849876287091, ['we', 'need', 'to', 'make', 'a', 'prediction', 'on', 'those', 'variables', 'in', 'return', 'the', 'results', 'and', \"that's\", 'it', 'so', 'if', 'you', 'remember', 'yesterday', 'where', 'we', 'left', 'off', 'with', 'Jacquelyn', \"she'd\", 'created', 'a', 'nice', 'function', 'that', 'was', 'just', 'to', 'return', 'to', 'bunch', 'of', 'predictions']), (0.006573487627417026, ['and', 'so', 'a', 'get', 'request', 'is', 'just', 'going', 'to', 'a', 'website', 'or', 'getting', 'any', 'information', 'from', 'the', 'internet', 'and', 'so', 'for', 'us', 'what', 'that', 'means', 'is', 'that', 'we', 'need', 'to', 'convert', 'the', 'variables', 'that', 'it', 'sends', 'to', 'us', 'so', 'I', 'can', 'use', 'it']), (0.006536966081535833, ['what', 'we', 'need', 'for', 'our', 'API', 'that', 'Jack', 'built', 'to', 'work', 'we', 'just', 'need', 'an', 'operating', 'system', 'the', 'correct', 'version', 'of', 'are', 'all', 'of', 'the', 'libraries', 'that', 'you', 'think', 'that', 'you', 'need']), (0.006536554658555365, ['the', 'first', 'project', 'at', 'T-Mobile', 'where', 'we', 'really', 'had', 'data', 'scientist', 'and', 'Engineers', 'a', 'machine-learning', 'people', 'on', 'the', 'room', 'side', 'by', 'side']), (0.006535703846265726, ['and', 'then', \"there's\", 'some', 'Lenox', 'libraries', 'we', 'have', 'to', 'import', 'python', 'because', 'carrots', 'runs', 'on', 'python', 'let', 'me', 'copy', 'over', 'our', 'scripts', 'install', 'are', 'libraries', 'open', 'up', 'the', 'port', 'and', 'then', 'just', 'say', 'run', 'the', 'main', 'function']), (0.0065337399113590345, ['is', 'there', 'a', 'what', 'this', 'means', 'that', 'you', 'can', 'run', 'docker']), (0.006531533672456438, ['is', 'it', 'okay', 'okay', 'so', \"it's\", 'built', 'on', 'something', 'simpler', 'somebody', 'else', 'with', 'a', 'lot', 'of', 'words', 'to', 'this', 'is', 'the', 'next', 'event', 'you', 'say', 'okay']), (0.0064521755559482155, ['6', 'lines', 'of', 'code']), (0.006398946721618576, ['but', 'if', 'you', 'know', 'what', 'shelter', 'who', 'wants', 'to', 'name', 'their', 'their', 'animals', 'from', 'Deep', 'learning', 'names', 'we', 'have', 'a', 'thing', 'that', 'you', 'can', 'have', 'any', 'point', 'and', 'sell', 'our', 'project', 'for', 'us', 'anybody', 'can', 'use', 'it', 'for', 'free', 'if', 'you', 'name', 'your', 'pet', 'after', 'any', 'of', 'these', 'names', 'generated', 'by', 'a', 'girl', 'that', 'work', 'I', 'will', 'give', 'you']), (0.006383080680646153, ['to', 'make', 'what', 'Jacqueline', 'put', 'on', 'the', 'screen', 'yesterday', 'into', 'an', 'API']), (0.006345190341639639, ['and', 'then', 'scaling', 'and', 'coordinating', 'is', 'easy', 'so', 'I', 'can', 'say', 'this', 'Docker', 'container', 'is', 'out', 'there', 'living', 'but', 'I', 'started', 'up', 'this', 'one', 'until', 'just', 'redirect', 'rap']), (0.00614061612623021, ['I', 'want', 'to', 'add', 'my', 'name', 'to', 'your', 'website', 'I', 'want', 'to', 'sign', 'up', 'for', 'a', 'mailing', 'list', 'so', \"here's\", 'my', 'name', 'website', 'and', 'do', 'whatever', 'you', 'want', 'with', 'it']), (0.00610734374553255, ['you', \"don't\", 'have', 'to', 'let', 'Engineers', 'take', 'away', 'your', 'work', 'even', 'levenger', 'companies', 'engineering', 'department', 'you', 'can', 'just', 'throw', 'it', 'up', 'on', 'AWS', 'and', 'it', 'it', 'all', \"that's\", 'out', 'the', 'same']), (0.006015752191050896, ['animarathon', 'which', 'is', 'like', 'cheap', 'kubernetes', 'does', 'the', 'does', 'the', 'release', 'so', 'it', 'puts', 'it', 'out', 'somewhere', 'on', 'to', 'the', 'internet']), (0.005980027653387841, ['thousands', 'of', 'thousands', 'of', 'lines', 'of', 'code', 'the', 'other', 'people']), (0.005816904288495143, ['and', 'so', \"we've\", 'already', 'done', 'that', 'on', 'our', 'laptops', 'to', \"let's\", 'talk', 'about', 'how', 'we', 'would', 'do', 'that', 'in', 'the', 'cloud']), (0.005794224198934611, ['but', 'you', 'guys', \"don't\", 'have', 'time', 'for', 'that']), (0.005738018009151629, ['double', 'extra', 'thank', 'you', 'to', 'my', 'son', 'who', 'allowed', 'both', 'of', 'his', \"mom's\", 'to', 'be', 'here', 'today', 'instead', 'of', 'hanging', 'out', 'with', 'him', 'especially', 'his', \"Mother's\", 'Day', 'weekend', 'and', 'then', 'the', 'code', 'is', 'available', 'on', 'GitHub', 'for', 'the', 'whole', 'thing', 'so', \"Jacqueline's\", 'neural', 'network', 'down', 'to', 'dockerizing', 'it', 'is', 'all', 'available', 'on', 'the', 'noelis', 'LLC']), (0.005658865469001184, ['you', 'just', 'run', 'your', 'function']), (0.005413424225202718, ['so', 'all', 'you', 'have', 'to', 'do', 'is', 'import', 'plumber']), (0.005396462584814632, ['I', 'know', 'we', 'do', 'that', 'at', 'T-Mobile', 'as', 'we', 'have', 'a', 'very', 'complicated', 'software', 'engineering', 'pipeline']), (0.00538324549979383, [\"there's\", 'a', 'thing', 'called', 'elastic', 'Container', 'Store', 'and', 'elastic', 'container', 'repository', 'Italy']), (0.005368662113771927, ['super', 'super', 'repeatable']), (0.005209179560028161, ['they', \"couldn't\", 'recreate', 'your', 'computer', 'if', 'somebody', 'turned', 'off', 'your', 'Sky', 'computer', 'they', \"couldn't\", 'recreate', 'it']), (0.005137925553005153, [\"it's\", 'a', 'Disney', 'pet', 'names', 'dockerfile', 'for', 'the', 'API']), (0.0051355917951987325, ['I', 'thought', 'you', 'felt', 'it', 'lives', 'on', 'your', 'laptop', 'you', 'have', 'an', 'API', 'and', 'hit', 'a', 'senior', 'API', 'sucks']), (0.005016443645808609, ['we', 'really', \"don't\", 'care', 'about', 'the', 'fancy', 'technology', 'that', \"you've\", 'applied']), (0.004980977417674522, [\"it's\", 'okay', 'just', 'have', 'a', 'starting', 'image', 'which', 'we', 'use', 'rocker', 'which', 'is', 'just', 'an', 'R', 'Docker', 'image']), (0.004965364738659935, ['Jackson', 'building', 'her', 'talk', 'yesterday']), (0.004865702400908659, ['the', 'first', 'thing', 'that', 'it', 'says', 'is', 'rocker', 'version']), (0.004860071324027088, ['sample', 'of', 'my', 'son', 'he', 'was', '16', 'months', 'old', 'at', 'the', 'time']), (0.004751044580650341, ['super', 'super', 'great']), (0.004679246675697378, ['No', 'less', 'llc.com', 'name', 'and', 'it', 'will', 'return', 'you', 'the', 'stuff', 'that', 'Jacksonville', 'yesterday', 'exactly', 'the', 'stuff', 'that', 'we', 'went', 'through']), (0.004520379450202067, ['and', 'we', 'do', 'that', 'with', 'plumber', 'which', 'is', 'a', 'package', 'developed', 'by', 'our', 'studio', 'that', 'is', 'literally', 'the', 'easiest', 'thing', 'in', 'the', 'entire', 'world']), (0.004477659469713266, ['Encore', 'you', 'can', 'bring', 'your', 'our', 'code', 'on', 'computers', 'that', \"don't\", 'have', 'are', 'installed']), (0.004389900203311288, ['but', \"there's\", 'a', 'trick', 'when', 'you', 'look', 'at', 'this']), (0.004386408390407759, [\"it's\", 'to', 'build', 'tools', 'that', 'actually', 'help', 'the', 'agent', 'help', 'you', 'faster']), (0.004370780508894542, ['that', 'probably', \"isn't\", 'good', 'engineering', 'to', 'just', 'set', 'up', 'a', 'virtual']), (0.0042604778871261515, ['thank', 'you']), (0.004260477887126151, ['thank', 'you']), (0.004221272819494077, ['but', 'that', 'front', 'line', 'and', 'kind', 'of', 'open', 'it', 'up']), (0.004184606419471112, ['plumber', 'yea']), (0.004088446129581585, ['and', 'so', 'since', 'good', 'engineering', 'is', 'repeatable']), (0.004061203938942472, ['so', 'you', 'can', 'look', 'at', 'it', 'Nike', 'okay', 'so', 'now', 'we', 'have', 'a', 'level', 'smaller', 'even']), (0.0039151811656032275, ['is', 'to', 'think', 'about', 'nesting', 'dolls', 'so', 'the', 'first', 'image', 'that', 'I', 'showed', 'you']), (0.0038497791055586207, ['now', 'we', 'have', 'some', 'other', 'thing', 'and', 'then', 'on', 'top', 'of', 'that', 'then']), (0.003803456423853178, [\"I'm\", 'Heather', 'noelis', 'and', 'I', 'was', 'the', 'first', 'machine', 'learning', 'engineer', 'hired', 'to', 'be', 'on', 'the', 'AIT', 'mat']), (0.0038017387654732484, ['show', 'Plumber', 'where', 'the', 'endpoints', 'are', 'in', 'a', 'limb', 'points', 'are', 'our', 'what', 'comes', 'after', 'the', '/', 'okay', 'went', 'to', 'weather.com', 'Seattle', 'the', 'endpoint', 'is', 'Seattle', 'part', 'of', 'the', 'URL']), (0.0037789276648938063, [\"it's\", 'a', \"what's\", 'left']), (0.003670173245077631, ['now', 'I', 'need', 'my', 'prop']), (0.0036459887742893906, [\"what's\", 'this']), (0.0033465262618990843, ['so', 'you', 'got', 'to', 'open', 'at', 'night', 'okay', 'so', 'finally', 'finally', 'we', 'reached', 'the', 'end']), (0.0033087316013306594, ['pergolas', 'to', 'essentially', 'build', 'a', 'tool', 'that', 'the', 'customer', 'can', 'interact', 'or', 'that', 'the', 'agent', 'can', 'interact', 'with', 'to', 'help', 'customers']), (0.003274304811333323, ['I', 'build', 'Java', 'services', 'in', 'this', 'is', 'way', 'easier']), (0.0031975856789994233, [\"there's\", 'another', 'one']), (0.003098533153622797, ['sure', 'but', 'that', 'also', 'has', 'an', 'import', 'line', \"it's\", 'from', 'Davion', 'which', 'is', 'an', 'operating', 'system']), (0.00309813755577088, [\"it's\", 'over', 'all', 'the', 'parties', 'are', 'giant', 'laptops', 'in', 'the', 'sky', 'that', 'somebody', 'else', 'owns']), (0.003047633177768545, ['and', 'you', 'can', 'follow', 'me', 'on', 'Twitter', 'at', 'heathercliff', 'they', 'talked', 'about', 'engineering']), (0.0030010340126752125, ['it', 'taught', 'us', 'that', 'the', 'disparities', 'between', 'the', 'two', 'disciplines', 'are', 'actually', 'very', 'small']), (0.002647904215222362, ['T-Mobile']), (0.002446780241120878, ['so', 'I', 'have', 'a', 'little', 'screenshot', 'of', 'a', 'sample', 'of', 'a', 'tool', 'that', 'we', 'have', 'that']), (0.0023010625118879626, ['so', 'I', 'can', 'just', 'my', 'old', 'models', 'hear', 'my', 'new', 'models', 'here', \"let's\", 'just']), (0.002257216610855839, ['weather.com', 'please', 'tell', 'me']), (0.0019571905237841043, ['this', 'is', 'kind', 'of', 'your', 'finished', 'product']), (0.001860959794436122, ['what', 'are', 'the', 'things', 'after', 'the', 'slash']), (0.0018568667794202141, ['incredibly', 'easy']), (0.0016740116908301097, ['I', 'should', 'be', 'giving', 'him', 'an', 'award', 'because', \"they're\", 'paying', 'for', 'my', 'house', 'at', 'the']), (0.0016709925866078038, ['working', 'on']), (0.0016627000243749947, ['which', 'words']), (0.0014265300245527885, ['a', 'whole', 'dollar']), (0.0013734996541225875, ['what', 'does', 'it', 'mean']), (0.0012819224713913886, ['three-point', 'whatever']), (0.00127316269136009, ['and', 'it', 'returns', 'a', 'result']), (0.001030927835051546, ['who', 'is', 'this']), (0.001030927835051546, ['what']), (0.001030927835051546, ['so', 'you', 'can', 'just', 'do', 'it']), (0.001030927835051546, ['so', 'what', 'can', 'we', 'do', 'that', 'is']), (0.001030927835051546, ['or', 'you', 'can', 'do', 'a']), (0.001030927835051546, ['how', 'can', 'we', 'document', 'this']), (0.001030927835051546, ['dark', 'and', 'heavy']), (0.001030927835051546, ['and', 'so', 'the', 'takeaways', 'are', 'that']), (0.001030927835051546, ['and']), (0.001030927835051546, ['Amber'])]\n",
      "Summarize Text: \n",
      " do you have the image which is after somebody builds that dockerfile and sets up the computer like you want that's the image and when you run it that's the container so people will throw these words that you will not but they're all really the same things just in different forms of the process. containers are cheaper there is less computational overhead cuz you don't need to use a whole computer every time there's super trendy so people think that you're doing really cutting-edge technology when you talk about it they're made to crash and be restarted so every time that you restart your computer it takes forever to restart a Docker container\n"
     ]
    }
   ],
   "source": [
    "generate_summary(\"converted.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreya Gokhe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('5f6d390eeebd3cf2661bd61b')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import gridfs\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.test_database  # use a database called \"test_database\"\n",
    "collection = db.files   # and inside that DB, a collection called \"files\"\n",
    "\n",
    "f = open('summary.txt')  # open a file\n",
    "text = f.read()    # read the entire contents, should be UTF-8 text\n",
    "\n",
    "# build a document to be inserted\n",
    "text_file_doc = {\"file_name\": \"summary.txt\", \"contents\" : text }\n",
    "# insert the contents into the \"file\" collection\n",
    "collection. insert(text_file_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"do you have the image which is after somebody builds that dockerfile and sets up the computer like you want that's the image and when you run it that's the container so people will throw these words that you will not but they're all really the same things just in different forms of the process\"\"do you have the image which is after somebody builds that dockerfile and sets up the computer like you want that's the image and when you run it that's the container so people will throw these words that you will not but they're all really the same things just in different forms of the process\", \"containers are cheaper there is less computational overhead cuz you don't need to use a whole computer every time there's super trendy so people think that you're doing really cutting-edge technology when you talk about it they're made to crash and be restarted so every time that you restart your computer it takes forever to restart a Docker container\"\n"
     ]
    }
   ],
   "source": [
    "text_file_d = collection.find_one({\"file_name\": \"summary.txt\", \"contents\" : text})\n",
    "print(text_file_d['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS \n",
    "import os \n",
    "import pyttsx3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The text that you want to convert to audio \n",
    "  \n",
    "# Language in which you want to convert \n",
    "language = 'en'\n",
    "\n",
    "s = str(text_file_d['contents']).strip('\"')    \n",
    "# Passing the text and language to the engine,  \n",
    "# here we have marked slow=False. Which tells  \n",
    "# the module that the converted audio should  \n",
    "# have a high speed \n",
    "myobj = gTTS(text=s, lang=language) \n",
    "  \n",
    "# Saving the converted audio in a mp3 file named \n",
    "# welcome  \n",
    "myobj.save(\"summ_speech.mp3\") \n",
    "  \n",
    "# Playing the converted file \n",
    "os.system(\"summ_spe.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
